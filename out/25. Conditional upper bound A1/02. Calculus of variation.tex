We will prove \Cref{thm:main-cap} by optimizing \(\mathcal{A}_1 : \mathcal{K}_\omega \to \mathbb{R}\). Here, we prepare a minimal amount of language needed to execute the calculus of variation to a concave quadratic functional \(f\) on a general convex space \(\mathcal{K}\). Later, we will show that our functional \(f = \mathcal{A}_1\) is concave and quadratic on the cap space \(\mathcal{K} = \mathcal{K}_\omega\), and then deploy the calculus of variation on \(\mathcal{A}_1\).

\begin{definition}

A \emph{convex space} is a set \(\mathcal{K}\) equipped with the \emph{convex combination} operation \(c_\lambda : \mathcal{K} \times \mathcal{K} \to \mathcal{K}\) for all \(\lambda \in [0, 1]\), such that the following list of equalities hold \cite{nlab-convex-space}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(c_0(x, y) = x\)
\item
  \(c_\lambda(x, x) = x\) for all \(\lambda \in [0, 1]\)
\item
  \(c_\lambda (x, y) = c_{1 - \lambda}(y, x)\) for all \(\lambda \in [0, 1]\)
\item
  \(c_\lambda(x, c_\mu(y, z)) = c_{\lambda \mu} (c_\tau(x, y), z)\) for all \(\lambda, \mu, \tau \in [0, 1]\) such that \(\lambda (1 - \mu) = (1 - \lambda \mu) \tau\).
\end{enumerate}

\label{def:convex-space}
\end{definition}

\begin{proposition}

The space of caps \(\mathcal{K}_\omega\) in \Cref{def:cap-space} is a convex space, equipped with the convex combination

\begin{align*}
c_\lambda(K_1, K_2) & := (1 - \lambda)K_1 + \lambda K_2 \\
& = \left\{ (1 - \lambda) p_1 + \lambda p_2 : p_1 \in K_1, p_2 \in K_2 \right\} 
\end{align*}
given by the Minkowski sum of convex bodies.

\label{pro:cap-space-convex-space}
\end{proposition}

\begin{proof}
It is rudimentary to verify all the axiomatic equations in \Cref{def:convex-space}.
\end{proof}

\begin{definition}

A function \(f : \mathcal{K} \to V\) from a convex space \(\mathcal{K}\) to a convex space \(V\) is \emph{convex-linear} if \(f(c_\lambda(K_1, K_2)) = c_\lambda(f(K_1), f(K_2))\) for all \(K_1, K_2 \in \mathcal{K}\) and \(\lambda \in [0, 1]\). Call a functional \(f : \mathcal{K} \to \mathbb{R}\) on \(\mathcal{K}\) a \emph{linear functional} on \(\mathcal{K}\) if it is convex-linear.

\label{def:convex-linear}
\end{definition}

\begin{definition}

For convex spaces \(\mathcal{K}\) and \(V\), call a function \(g : \mathcal{K} \times \mathcal{K} \to V\) \emph{convex-bilinear} if the maps \(K \mapsto g(K_1, K)\) and \(K \mapsto g(K, K_2)\) are convex-linear for any fixed \(K_1, K_2 \in \mathcal{K}\).

\label{def:convex-bilinear}
\end{definition}

\begin{definition}

Call \(h : \mathcal{K} \to \mathbb{R}\) a \emph{quadratic functional} on a convex space \(\mathcal{K}\), if \(h(K) = g(K, K)\) for some convex-bilinear function \(g : \mathcal{K} \times \mathcal{K} \to \mathbb{R}\).

\label{def:convex-space-quadratic}
\end{definition}

The \emph{directional derivative} of a quadratic functional \(f\) on a convex space \(\mathcal{K}\) is the key for executing the calculus of variation on \(f\).

\begin{definition}

For any quadratic functional \(f : \mathcal{K} \to \mathbb{R}\) on a convex space \(\mathcal{K}\) and \(K, K' \in \mathcal{K}\), define the \emph{directional derivative}
\[
Df(K; K') = \left. \frac{d}{d \lambda} \right|_{\lambda = 0} f(c_\lambda(K, K'))
\]
of \(f\) at \(K\) from \(K\) to \(K'\).

\label{def:convex-space-directional-derivative}
\end{definition}

\Cref{def:convex-space-directional-derivative} can be seen as a generalization of the Gateaux derivative to functionals on a general convex space. For any quadratic functional \(f\) and a fixed \(K \in \mathcal{K}\), the value \(Df(K; K')\) is well-defined and always a linear functional of \(K'\).

\begin{lemma}

Let \(f\) be a quadratic functional on a convex space \(\mathcal{K}\), so that \(f(K) = h(K, K)\) for a convex-bilinear map \(h : \mathcal{K} \times \mathcal{K} \to \mathbb{R}\). Then we have the following for any \(K, K' \in \mathcal{K}\).
\[
Df(K; K') = h(K, K') + h(K', K) - 2 h (K, K)
\]
So in particular, the map \(Df(K; -) : \mathcal{K} \to \mathbb{R}\) is always well-defined and a linear functional.

\label{lem:derivative-calculation}
\end{lemma}

\begin{proof}
We have
\begin{equation}
\label{eqn:quadratic-functional}
\begin{split}
f(c_\lambda(K, K')) & = h(c_\lambda(K, K'), c_\lambda(K, K')) \\
& = (1 - \lambda)^2 h(K, K) + \lambda (1 - \lambda) \left( h(K, K') + h (K', K) \right) + \lambda^2 h(K', K')
\end{split}
\end{equation}
by bilinearity of \(h\). Now take the derivative at \(\lambda = 0\).
\end{proof}

\begin{definition}

A functional \(f : \mathcal{K} \to \mathbb{R}\) on a convex space \(\mathcal{K}\) is \emph{concave} (resp. \emph{convex}) if \(f(c_\lambda(K_1, K_2)) \geq (1 - \lambda) f(K_1) + \lambda f(K_2)\) (resp. \(f(c_\lambda(K_1, K_2)) \leq (1 - \lambda) f(K_1) + \lambda f(K_2)\)) for all \(K_1, K_2 \in \mathcal{K}\) and \(\lambda \in [0, 1]\).

\label{def:convex-space-concavity}
\end{definition}

To prove that \(K\) maximizes a concave quadratic functional \(f(K)\) on \(\mathcal{K}\), we only need to prove that \(Df(K; -)\) is a nonpositive linear functional on \(\mathcal{K}\).

\begin{theorem}

For any concave quadratic functional \(f\) on a convex space \(\mathcal{K}\), the value \(K \in \mathcal{K}\) maximizes \(f(K)\) if and only if the linear functional \(Df(K; -)\) is nonpositive.

\label{thm:quadratic-variation}
\end{theorem}

\begin{proof}
Assume that \(K\) is the maximizer of \(f(K)\). Then for any \(K' \in \mathcal{K}\), the value \(f(c_\lambda(K, K'))\) over all \(\lambda \in [0, 1]\) is maximized at \(\lambda = 0\). So taken derivative at \(\lambda = 0\), we should have \(Df(K; K') \leq 0\).

Now assume on the other hand that \(K \in \mathcal{K}\) is chosen such that \(Df(K; -)\) is always nonpositive. Take an arbitrary \(K' \in \mathcal{K}\) and fix it. Observe that \(f(c_\lambda(K, K'))\) is a polynomial \(p(\lambda)\) of \(\lambda \in [0, 1]\) by \Cref{eqn:quadratic-functional}. Because \(f\) is concave, the polynomial \(p(\lambda)\) is also concave with respect to \(\lambda\) and the quadratic coefficient of \(p(\lambda)\) is nonpositive. The linear coefficient of \(p(\lambda)\) is \(Df(K; K')\) which is nonpositive as well. So \(p(\lambda)\) is monotonically decreasing with respect to \(\lambda\) and we have \(f(K) \geq f(K')\) as desired.
\end{proof}