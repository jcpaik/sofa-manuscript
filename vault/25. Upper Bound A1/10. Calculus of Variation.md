In this section, we invoke calculus of variation on $\mathcal{A}_1$. We will also prepare enough materials reusable for the next upper bound A2.

> __Theorem [convex-curve-area-functional-variation].__ Let $\mathbf{x}_1$ and $\mathbf{x}_2$ be two different convex curves with the same angle interval $[t_1, t_2] \subseteq S^1$. Then for every $\lambda \in [0, 1]$, the curve  we have the following.
> ^thm-convex-curve-area-functional-variation

_Proof._ Define the following for two convex bodies $K_1$ and $K_2$.
$$
V(K_1, K_2) = \frac{1}{2} \int_{S^1}p_{K_1}(t)\,\beta_{K_2}(dt)
$$
By [[yy. Geometric Results#^thm-boundary-measure-area]] we have $V(K, K)$ equal to the area $|K|$ of $K$ for any $K$, and by [[yy. Geometric Results#^thm-convex-body-linear]] $V(K_1, K_2)$ is multilinear with respect to each variable. So $V(K_1, K_2)$ is the mixed volume [[@sangwine-yagerMixedVolumes1993]] of $K_1$ and $K_2$ (say, because $2V(K_1, K_2) = |K_1 + K_2| - |K_1| - |K_2|$). By multilinearlity and reflexivity of the mixed volume $V$, for $K = (1 - \lambda) K_1 + \lambda K_2$ we have the following.
$$
\begin{align*}
\left. \frac{d}{d\lambda} \right|_{\lambda=0} |K| & = \left. \frac{d}{d\lambda} \right|_{\lambda=0} V(K, K) =  \\
& = \left. \frac{d}{d\lambda} \right|_{\lambda=0} (1-\lambda)^2 V(K_1, K_1) + 2 \lambda (1 - \lambda) V(K_1, K_2) + \lambda^2 V(K_2, K_2)  \\
& = - 2 V(K_1, K_1) + 2 V(K_1, K_2)  \\
& = \int_{S^1} (p_{K_2}(t) - p_{K_1}(t)) \, \beta_{K_1}(dt)
\end{align*}
$$
□

As $\mathcal{A}_1$ is a convex function, any local maximizer of $\mathcal{A}_1$ is also a global maximizer of $\mathcal{A}_1$. Now with [[01. Space of Caps#^thm-variation-maximizer]], it suffices to find some $K_1$ so that for any $K_2$ and $K = (1 - \lambda)K_1 + \lambda K_2$ for $\lambda \in [0, 1]$, we have the calculus of variation $\left. \frac{d}{d\lambda} \right|_{\lambda = 0} \mathcal{A}_1(K) = 0$.

> __Definition [i-cap].__ For any cap $K$, define $i_K : J_\omega \to \mathbb{R}$ as $i_K(t) = h_K^+(t) - 1$ and $i_K(t + \pi / 2) = g^+_K(t) - 1$ for $t \in [0, \omega]$. ^def-i-cap
 
> __Theorem [variation-a1].__ Let $K_1$ and $K_2$ be two caps in $\mathcal{K}_\omega$. Define $K= (1-\lambda)K_1 + \lambda K_2$ as the interpolation between $K_1$ and $K_2$ with $0 \leq \lambda \leq 1$. Then we have the following calculation. ^thm-variation-a1
$$
\left. \frac{d}{d\lambda} \right|_{\lambda = 0} \mathcal{A}_1(K)
= \left< p_{K_2} - p_{K_1}, \beta_{K_1} - i_{K_1}(t)dt \right>
$$



_Proof._ We start from [[05. Definition#^thm-a1-formula]].
$$
\begin{align*}
\mathcal{A}_1(K) = \frac{1}{2} \int_{J_\omega} p_K(t) \beta_K(dt) - 
\frac{1}{2} \int_{[0, \omega]} \mathbf{x}_K(t) \times \mathbf{x}'_K(t) dt
\end{align*}
$$

By applying [[yy. Geometric Results#^thm-boundary-measure-area-variation]] to the first term and applying [[yy. Geometric Results#^thm-variation-curve]] to the second term, we reach the following.
$$
\left. \frac{d}{d\lambda} \right|_{\lambda = 0} \mathcal{A}_1(K)
= \int_{t \in [0, \omega]} (p_{K_2} (t) - p_{K_1}(t)) \beta_{K_1} (dt) - 
\int_0^\omega (\mathbf{x}_{K_2} - \mathbf{x}_{K_1}) \times d\mathbf{x}_{K_1}(t)
$$
Let's focus on the second term more. We write each vector as linear combinations of $u_t$ and $v_t$. This follows from definition of $\mathbf{x}_K$.
$$
\mathbf{x}_{K_2} - \mathbf{x}_{K_1} = (p_{K_2} (t) - p_{K_1} (t)) u_t + 
(p_{K_2} (t + \pi / 2) - p_{K_1} (t + \pi / 2))) v_t
$$
And [[01. Space of Caps#^thm-inner-corner-deriv]] gives the following almost everywhere.
$$
\mathbf{x}'_{K_1} = \mathbf{v}_{K_1}(t) = -(g_{K_1}^+(t) - 1) \cdot u_t + (h_{K_1}^+(t) - 1) \cdot v_t
$$
So the cross-product $(\mathbf{x}_{K_2} - \mathbf{x}_{K_1}) \times \mathbf{x}'_{K_1}$ is equal to the following almost everywhere.
$$
(h_K^+(t) - 1) (p_{K_2} (t) - p_{K_1} (t)) + (g_K^+(t) - 1) (p_{K_2} (t + \pi / 2) - p_{K_1} (t + \pi / 2)))
$$
Using [[#^def-i-cap]], the second integral can be expressed more concisely.
$$
\int_0^\omega (\mathbf{x}_{K_2} - \mathbf{x}_{K_1}) \times d\mathbf{x}_{K_1}(t) = 
\int_{t \in J_\omega} (p_{K_2} (t) - p_{K_1}(t)) i_{K_1}(t) dt
$$
We get the original equation by plugging this back to the equation for $\left. \frac{d}{d\lambda} \right|_{\lambda = 0} \mathcal{A}_1(K)$. □
