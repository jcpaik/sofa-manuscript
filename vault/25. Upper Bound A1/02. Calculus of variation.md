Observe that the space of caps $\mathcal{K}_\omega$ is a _convex space_ equipped with the barycentric combination operation $c_\lambda(-, -)$ [[@nlab-convex-space]].

> __Definition [convex-space].__ A _convex space_ is a set $\mathcal{K}$ equipped with the _convex combination_ operation $c_\lambda : \mathcal{K} \times \mathcal{K} \to \mathcal{K}$ for all $\lambda \in [0, 1]$, such that the followings hold. ^def-convex-space
> 
> 1. $c_0(x, y) = x$
> 2. $c_\lambda(x, x) = x$ for all $\lambda \in [0, 1]$
> 3. $c_\lambda (x, y) = c_{1 - \lambda}(y, x)$ for all $\lambda \in [0, 1]$
> 4. $c_\lambda(x, c_\mu(y, z)) = c_{\lambda \mu} (c_\tau(x, y), z)$ for all $\lambda, \mu, \tau \in [0, 1]$ such that $\lambda (1 - \mu) = (1 - \lambda \mu) \tau$.

> __Proposition [cap-space-convex-space].__ The space of caps $\mathcal{K}_\Theta$ in [[00. Sofa area functional#^def-cap-space]] is a convex space, equipped with the convex combination
$$
\begin{align*}
c_\lambda(K_1, K_2) & = (1 - \lambda)K_1 + \lambda K_2 \\
& = \left\{ (1 - \lambda) p_1 + \lambda p_2 : p_1 \in K_1, p_2 \in K_2 \right\} 
\end{align*}
$$
> given by Minkowski sum of convex bodies. ^pro-cap-space-convex-space

We will prove [[00. Sofa area functional#^thm-main-cap]] by optimizing $\mathcal{A}_1$ with calculus of variation. Here, we prepare a minimal amount of language needed to execute the calculus of variation on a quadratic functional defined on a general convex space $\mathcal{K}$.

> __Definition [convex-linear].__ A function $f : \mathcal{K} \to V$ from a convex space $\mathcal{K}$ to a convex space $V$ is _convex-linear_ if $f(c_\lambda(K_1, K_2)) = c_\lambda(f(K_1), f(K_2))$ for all $K_1, K_2 \in \mathcal{K}$ and $\lambda \in [0, 1]$. Call a functional $f : \mathcal{K} \to \mathbb{R}$ on $\mathcal{K}$ a _linear functional_ on $\mathcal{K}$ if it is convex-linear. ^def-convex-linear

> __Definition [convex-bilinear].__ For convex spaces $\mathcal{K}$ and $V$, call a function $g : \mathcal{K} \times \mathcal{K} \to V$ _convex-bilinear_ if the maps $K \mapsto g(K_1, K)$ and $K \mapsto g(K, K_2)$ are convex-linear for any fixed $K_1, K_2 \in \mathcal{K}$. ^def-convex-bilinear

> __Definition [convex-space-quadratic].__ Call $h : \mathcal{K} \to \mathbb{R}$ a _quadratic functional_ on a convex space $\mathcal{K}$, if $h(K) = g(K, K)$ for some convex-bilinear function $g : \mathcal{K} \times \mathcal{K} \to \mathbb{R}$. ^def-convex-space-quadratic

> __Definition [convex-space-directional-derivative].__ For any quadratic functional $f : \mathcal{K} \to \mathbb{R}$ on a convex space $\mathcal{K}$ and $K, K' \in \mathcal{K}$, define: ^def-convex-space-directional-derivative
$$
Df(K; K') = \left. \frac{d}{d \lambda} \right|_{\lambda = 0} f(c_\lambda(K, K'))
$$

[[02. Calculus of variation#^def-convex-space-directional-derivative]] can be seen as a generalization of the Gateaux derivative to functionals on a general convex space. For any quadratic functional $f$ and a fixed $K \in \mathcal{K}$, the value $Df(K; K')$ is well-defined and always a linear functional of $K'$.

> __Lemma [derivative-calculation].__ Let $f$ be a quadratic functional on a convex space $\mathcal{K}$, so that $f(K) = h(K, K)$ for a convex-bilinear map $h : \mathcal{K} \times \mathcal{K} \to \mathbb{R}$. Then we have the following for any $K, K' \in \mathcal{K}$. ^lem-derivative-calculation
$$
Df(K; K') = h(K, K') + h(K', K) - 2 h (K, K)
$$
> So in particular, the map $Df(K; -) : \mathcal{K} \to \mathbb{R}$ is always well-defined and a linear functional. 

_Proof._ We have the following computation by bilinearlity of $h$. ^eqn-quadratic-functional
$$
\begin{align*}
f(c_\lambda(K, K')) & = h(c_\lambda(K, K'), c_\lambda(K, K')) \\
& = (1 - \lambda)^2 h(K, K) + \lambda (1 - \lambda) \left( h(K, K') + h (K', K) \right) + \lambda^2 h(K', K')
\end{align*}
$$
Now take derivative at $\lambda = 0$. □

> __Definition [convex-space-concavity].__ A functional $f : \mathcal{K} \to \mathbb{R}$ on a convex space $\mathcal{K}$ is _concave_ (resp. _convex_) if $f(c_\lambda(K_1, K_2)) \geq (1 - \lambda) f(K_1) + \lambda f(K_2)$ (resp. $f(c_\lambda(K_1, K_2)) \leq (1 - \lambda) f(K_1) + \lambda f(K_2)$) for all $K_1, K_2 \in \mathcal{K}$ and $\lambda \in [0, 1]$. ^def-convex-space-concavity

To prove that $K$ maximizes a concave quadratic functional $f(K)$ on $\mathcal{K}$, we only need to prove that $Df(K; -)$ is a nonpositive linear functional on $\mathcal{K}$.

> __Theorem [quadratic-variation].__ For any concave quadratic functional $f$ on a convex space $\mathcal{K}$, the value $K \in \mathcal{K}$ maximizes $f(K)$ if and only if the linear functional $Df(K; -)$ is nonpositive. ^thm-quadratic-variation

_Proof._ Assume that $K$ is the maximizer of $f(K)$. Then for any $K' \in \mathcal{K}$, the value $f(c_\lambda(K, K'))$ over all $\lambda \in [0, 1]$ is maximized at $\lambda = 0$. So taken derivative at $\lambda = 0$, we should have $Df(K; K') \leq 0$.

Now assume on the other hand that $K \in \mathcal{K}$ is chosen such that $Df(K; -)$ is always nonpositive. Take an arbitrary $K' \in \mathcal{K}$ and fix it. Observe that $f(c_\lambda(K, K'))$ is a polynomial $p(\lambda)$ of $\lambda \in [0, 1]$ by [[02. Calculus of variation#^eqn-quadratic-functional]]. Because $f$ is concave, the polynomial $p(\lambda)$ is also concave with respect to $\lambda$ and the quadratic coefficient of $p(\lambda)$ is nonpositive. The linear coefficient of $p(\lambda)$ is $Df(K; K')$ which is nonpositive as well. So $p(\lambda)$ is monotonically decreasing with respect to $\lambda$ and we have $f(K) \geq f(K')$ as desired. □