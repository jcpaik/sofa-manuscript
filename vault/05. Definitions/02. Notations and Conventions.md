As we need a lot of notations, we quickly run out of symbols to use. In this paper, we circumvent this problem by overriding the same symbol with different number of subscripts. For example, the symbols $u$, $u_t$ and $u_{K, t}$ may denote something drastically different. If $u_t$ is a value depending on an mathematical object $u$ (e.g. entries of a matrix), then we explicitly define so before assuming so.

We set up basic notions and conventions that will be throughly used in the rest of the document.

# Geometric Primitives

We use the convention $S^1 \simeq \mathbb{R} / 2 \pi \mathbb{Z}$. For any function $f$ on $S^1$ and any $t \in \mathbb{R}$, we define $f(t)$ as the value $f(t + 2 \pi \mathbb{Z})$. That is, a real value coerces to a value in $S^1$ when used as an argument of a function that takes a value in $S^1$. We define tangent lines and corresponding half-planes of an arbitrary shape $S \subset \mathbb{R}^2$.

> __Definition [frame].__ For any angle $t$ in $S^1 \simeq \mathbb{R}^2/2\pi\mathbb{Z}$ or $\mathbb{R}$, define the unit vectors $u_t = \left( \cos t, \sin t \right)$ and $v_t = \left( -\sin t,\cos t \right)$. Note that the unit vectors $u_t$ and $v_t$ form a frame with orthonormal basis of $\mathbb{R}^2$ rotated counterclockwise by an angle of $t$. ^def-frame

> __Definition [support-function].__ For any shape $S$, define its _support function_ $p_S : S^1 \to \mathbb{R}$ as the value $p_S(t) = \sup \left\{ p \cdot u_t : p \in S \right\}$. ^def-support-function

> __Definition [line].__ For any angle $t$ in $S^1 \simeq \mathbb{R}^2/2\pi\mathbb{Z}$ or $\mathbb{R}$, and a value $h \in \mathbb{R}$, define the line $l(t, h)$ with the _normal angle_ $t$ and the distance $h$ from the origin as the following. ^def-line
$$
l(t, h) = \left\{ p \in \mathbb{R}^2 : p \cdot u_t = h \right\}
$$
> Also, define the line $l(t) = l(t, 0)$ that passes through the origin.

> __Definition [tangent-line].__ For any shape $S$ and angle $t \in S^1$, define the _tangent line_ $l_S(t)$ of $S$ with _normal angle_ $t$ as the line $l_S(t) = l(t, p_S(t))$. ^def-tangent-line

> __Definition [half-plane].__ For any angle $t$ in $S^1 \simeq \mathbb{R}^2/2\pi\mathbb{Z}$ or $\mathbb{R}$, and a value $h \in \mathbb{R}$, define the half-plane $H(t, h)$ with the boundary $l(t, h)$ as the following. We say that the half-plane $H(t, h)$ has the _normal angle_ $t$. ^def-half-plane
$$
H(t, h) = \left\{ p \in \mathbb{R}^2 : p \cdot u_t \leq h \right\}
$$
> Also, define its interior as the following.
$$
H^\circ(t, h) = \left\{ p \in \mathbb{R}^2 : p \cdot u_t < h \right\}
$$

> __Definition [tangent-half-plane].__ For any shape $S$ and angle $t \in S^1$, define the _tangent half-plane_ $H_S(t)$ of $S$ with _normal angle_ $t$ as the line $H_S(t) = H(t, p_S(t))$. ^def-tangent-line

The following notions will be useful in the construction of upper bounds of sofa area. 

> __Definition [ray].__ For any point $p \in \mathbb{R}^2$ and an angle $t \in S^1$, define $R_p(t)$ as the closed _ray_ (or _half-line_) in the direction of $u_t$ starting from the point $p$. ^def-ray

> __Definition [closed-in-direction].__  Say that a subset $X$ of $\mathbb{R}^2$ is _closed in the direction_ of $u_t$ (_angle_ $t$) if for any point $p \in X$, the ray $R_p(t)$ is contained in $X$. We say that a set $X$ is _closed in the direction downwards_ (resp. _upwards_) if $X$ is closed in the direction of angle $3\pi/2$ (resp. $\pi/2$). ^def-closed-in-direction

> __Definition [further-in-direction].__ Say that a point $p_0$ is _further_ (resp. _strictly further_) _than_ $p_1$ _in the direction of_ nonzero vector $v \in \mathbb{R}^2$ if and only if $p_0 \cdot v \geq p_1 \cdot v$ (resp. $p_0 \cdot v > p_1 \cdot v$). Say that a point $p_0$ strictly lies left (resp. right) to the point $p_1$ if and only if $p_0 \cdot u_0 < p_1 \cdot u_0$ (resp. $p_0 \cdot u_0 > p_1 \cdot u_0$). ^def-further-in-direction

# Convex Bodies

We set up notions related to a two-dimensional convex body.

> __Definition [convex-body].__ A _convex body_ $K$ is a nonempty compact subset of $\mathbb{R}^2$ which is an intersection of [[02. Notations and Conventions#^def-half-plane|half-planes]]. ^def-convex-body

> __Definition [convex-body-edge].__ For any convex body $K$ and $t \in S^1$, define the _edge_ $e_K(t)$ of $K$ as the intersection of $K$ with the tangent line $l_K(t)$. By convexity and compactness of $K$, $e_K(t)$ is a point or a closed line segment. Let $v_K^+(t)$ and $v_K^-(t)$ be the endpoints of the line segment $e_K(t)$ such that $v_K^+(t)$ is positioned farthest in the direction of $v_t$ and $v_K^-(t)$ is positioned farthest in the opposite direction of $v_t$. ^def-convex-body-edge

> __Figure [convex-body].__ A convex body $K$ with its edge, vertices, tangent line, and half-plane. ^fig-convex-body
> 
> ![50%](images/convex-body.svg)

> __Definition [convex-body-supported].__ A convex body $K$ is _supported by_ a closed set $\Theta \subseteq S^1$ if $K$ is an intersection of half-planes with normal angles in $\Theta$. That is, $K = \bigcap_{t \in \Theta} H_K(t)$. ^def-convex-body-supported

For example, the unit square $[0, 1]^2$ is supported by the set $\{0, \pi/2, \pi, 3\pi/2\}$.

# Analysis

A lot of functions used here will have left/right limits/differentiations of different values. So we define notions for such limits/differentiations. 

> __Definition [left-right-limit].__ For any function $f : \mathbb{R} \to \mathbb{R}$ or $f : S^1 \to \mathbb{R}$, $f(t-)$ denotes the left limit of $f$ at $t$ and $f(t+)$ denotes the right limit of $f$ at $t$. ^def-left-right-limit

> __Definition [left-right-differentiation].__ For any function $f : X \to \mathbb{R}$ defined on some open subset $X$ of either $\mathbb{R}$ and $S^1$, and $t \in X$, define $\partial^+f(t)$ and $\partial^-f(t)$ as the right and left differentiation of $f$ at $t$ if they exists. ^def-left-right-differentiation

If $\mu$ is a Borel measure on an interval $I$ of $\mathbb{R}$, and $X$ is a measurable subset of $I$, denote the Lebesgue integral of a measurable function $f$ on $X$ as $\int_{X}f\,d \mu$ (no parametrization) or $\int_X f(t)\,\mu(dt)$ (parametrization with $t \in X$). The notation $\int_a^b f(t) \, \mu(dt)$ means the integral $\int_{(a, b]} f(t)\,\mu(dt)$. That is, $\int_a^b$ denotes the integration on the half-open interval $(a, b]$.

Recall the notion of _Lebesgue-Stieltjes measure_ [[@halmos2013measure]].

> __Definition [lebesgue-stieltjes-measure].__ For any right-continuous, bounded-variation function $F : I \to \mathbb{R}$ on any interval $I$ open on the left side ($\mathbb{R}$, $(a, \infty)$, $(a, b)$, or $(a, b]$) there is a unique signed Borel measure $dF$ called the _Lebesgue-Stieltjes measure_ on $I$ such that $dF\left( (a, b] \right) = F(b) - F(a)$ for any interval $(a, b]$ in $I$. ^def-lebesgue-stieltjes-measure

If $\mu = dF$ is the Lebesgue-Stieltjes measure of a function $F$, then instead of writing the integral $\int_X f\,d(dF)$ we just write $\int_X f\,dF$. Also instead of writing $\int_X f(t)\, dF(dt)$ we write $\int_X f(t)\,dF(t)$. Linearity $d(c F) = c dF$ and $d(F+G) = dF + dG$ holds for real $c$ and functions $F, G$. But we don't have the product formula $d(FG) = dF \cdot G + F \cdot dG$ in general. For example, assume that both $F$ and $G$ are functions $1_{\geq 0}$. Then $FG = 1_{\geq0}$ as well, but we have $d(1_{\geq0})$ equal to the Dirac measure $\delta$ with mass 1 concentrated at zero, so $d(FG) = \delta$ while $dF \cdot G + F \cdot dG = 2 \delta$. Therefore, some care has to be made. We have the following general version of integration by parts [[@revuz2013continuous]].

> __Theorem [integration-by-parts].__ Let $F, G : [a, b] \to \mathbb{R}$ be right-continuous and bounded-variation functions. Then we have the following. ^thm-integration-by-parts
$$
F(b)G(b) = F(a)G(a) + \int_{(a, b]} F(t) \, dG(t) + \int_{(a, b]} G(t-) \, dF(t)
$$

Then the product formula is justified when one of the functions is continuous.

> __Corollary [product-rule-differential].__ Let $F, G : I \to \mathbb{R}$ be right-continuous and bounded-variation on some interval $I$. If either $F$ or $G$ is continuous, then we have $d(FG) = F dG + G dF$. ^cor-product-rule-differential

_Proof._ Assume $G$ is continuous. By Carathéodory's extension theorem, it is sufficient to justify that the measure of both $d(FG)$ and $FdG + GdF$ agrees on any $(a, b] \subseteq I$. Using the definitions and that $G(t-) = G(t)$ this is exactly [[#^thm-integration-by-parts]]. If $F$ is continuous we can just flip the roles of $F$ and $G$. □

# Curves

We adopt the definition of curves in [[@apostolMathematicalAnalysisModern]].

> __Definition [curve].__ Let $\alpha : [a, b] \to \mathbb{R}^2$ be a continuous function with $a < b$. A _curve_ $\Gamma$ _parametrized by_ $\alpha$ is the image $\Gamma$ of $\alpha$ equipped with the particular _parametrization_ $\alpha$, and we say that the curve $\Gamma$ _joins_ the points $\alpha(a)$ and $\alpha(b)$. If $\alpha(a)=\alpha(b)$ then the curve $\Gamma$ is a _closed curve_. If $\alpha(a) \neq \alpha(b)$ then the curve $\Gamma$ is an _arc_. If $\alpha$ is one-to-one then the curve $\Gamma$ is a _Jordan arc_. If $\alpha$ is one-to-one on $[a, b)$ and $\alpha(a) = \alpha(b)$ then the curve $\Gamma$ is a _Jordan curve_.
> 
> If $\Gamma_1$ and $\Gamma_2$ are curves with parametrizations $\alpha : [a, b] \to \mathbb{R}^2$ and $\beta : [c, d] \to \mathbb{R}^2$ respectively and the endpoints $\alpha(b) = \beta(c)$ match, define the _join_ of $\Gamma_1$ and $\Gamma_2$ as the union $\Gamma_1 \cup \Gamma_2$ parametrized by $\gamma(t) : [a, b + (d-c)] \to \mathbb{R}^2$ defined as $\gamma(t) = \alpha(t)$ for $t \leq b$ and $\gamma(t) = \beta(t - b + c)$ for $t > b$. ^def-curve

Note that although we typically say that the image $\Gamma$ of parametrization $\alpha$ is a curve, the curve is actually the datum $(\Gamma, \alpha)$ of both the image $\Gamma$ and its parametrization $\alpha$. The area of the region enclosed by a Jordan curve can be expressed as the followign value.

> __Definition [curve-area-functional].__ Let $\Gamma$ be any rectifiable curve equipped with a parametrization $\mathbf{x} : [a, b] \to \mathbb{R}^2$. Write $\mathbf{x}(t) = (x(t), y(t))$. Define the _curve area functional_ $I(\mathbf{x})$ of $\Gamma$ as the following. ^def-curve-area-functional
$$
I(\mathbf{x}) = \frac{1}{2} \int_a^b \mathbf{x}(t) \times d\mathbf{x}(t) = \frac{1}{2} \int_a^b x(t) dy(t) - y(t) dx(t)
$$
> Note that $\mathbf{x}(t)$ is rectifiable so is of bounded variation. So the Lebesgue-Stieltjes measure $d \mathbf{x}(t) = (dx(t), dy(t))$ exists and the integral is well-defined. Also, write $I(p, q)$ for the area functional of the line segment $\mathbf{x}$ connecting point $p$ to $q$. Then we have $I(p, q) = 1/2 \cdot (p \times q)$ where the cross product $(a, b) \times (c, d)$ of two vectors in $\mathbb{R}^2$ is defined as $ad-b c$.

If $\mathbf{x}$ is closed, $I(\mathbf{x})$ measures the signed area of the region enclosed by $\mathbf{x}$. If $\mathbf{x}$ is a Jordan curve, it measures the exact area enclosed by $\mathbf{x}$ with the sign depending on the orientation of $\mathbf{x}$ ([[03. Geometric Results#^thm-green]]). In general where $\mathbf{x}$ might not be closed, $I(\mathbf{x})$ measures the signed area of the region bounded by the line segment connecting origin and $\mathbf{x}(a)$, the curve $\mathbf{x}$, and then the line segment connecting $\mathbf{x}(b)$ and the origin in order. Note that if $\gamma$ is the join of two curves $\alpha$ and $\beta$ then $I(\gamma) = I(\alpha) + I(\beta)$; this will useful in decomposing the area enclosed by the join of multiple curves.