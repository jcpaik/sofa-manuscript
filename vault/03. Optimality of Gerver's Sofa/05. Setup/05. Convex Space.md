We will reduce the moving sofa problem to the maximization of a concave quadratic functional on a convex domain. A (cancellative) convex space is essentially a convex subset of a vector space equipped with a barycentric operation.

> __Theorem [convex-spaces].__ (Theorem 2 of [@stonePostulatesBarycentricCalculus1949]; see [@nlab-convex-space]) A _cancellative convex space_ $\mathcal{V}$ is a space with the barycentric operation $c_\lambda : \mathcal{V} \times \mathcal{V} \to \mathcal{V}$ for all $\lambda \in [0, 1]$, such that there is an injective embedding $e : \mathcal{V} \to V$ to a vector space $V$ such that $e(c_{\lambda}(v_1, v_2)) = (1 - \lambda) e(v_1) + \lambda e(v_2)$. ^thm-convex-spaces

> __Definition [convex-spaces].__ In this paper, call a _cancellative convex space_ simply a _convex domain_. ^def-convex-spaces

> __Definition [convex-linear].__ In this paper, call a function $f : \mathcal{V}_1 \to \mathcal{V}_2$ between convex domains _linear_ if it preserves the barycentric operation $c_\lambda$. ^def-convex-linear

> __Definition [convex-bilinear].__ In this paper, call a function $g : \mathcal{V}_1 \times \mathcal{V}_2 \to \mathcal{V}_3$ _bilinear_ if the maps $v \mapsto g(v_1, v)$ and $v \mapsto g(v, v_2)$ are linear for any fixed $v_1 \in \mathcal{V}_1, v_2 \in \mathcal{V}_2$. ^def-convex-bilinear

> __Definition [convex-space-quadratic].__ Call $h : \mathcal{V} \to \mathbb{R}$ a _quadratic functional_ on a convex domain $\mathcal{V}$ if $h(K) = g(K, K)$ for some bilinear $g : \mathcal{V} \times \mathcal{V} \to \mathbb{R}$. ^def-convex-space-quadratic

> __Remark [convex-linear-convention].__ Note that [[#^def-convex-linear]], [[03. Optimality of Gerver's Sofa/05. Setup/05. Convex Space#^def-convex-bilinear]], and [[03. Optimality of Gerver's Sofa/05. Setup/05. Convex Space#^def-convex-space-quadratic]] means _affine_-linearity instead of the usual linearity on vector spaces. So in particular, we call an affine map between vector spaces that does not preserve the origin _linear_ in this paper. ^rem-convex-linear-convention

Recall that the _Minkowski sum_ $K_1 + K_2$ of two convex bodies $K_1, K_2$ is defined as
$$
K_1 + K_2 = \left\{ p_1 + p_2 : p_1 \in K_1, p_2 \in K_2 \right\}.
$$
For any convex body $K$, its _dilation_ $aK$ by a constant $a \in \mathbb{R}$ is defined as
$$
aK = \left\{ ap : p \in K \right\}.
$$

> __Theorem [convex-body-space].__ The space $\mathcal{K}$ of all planar convex bodies is a convex domain with the barycentric operation ^thm-convex-body-space
$$
\begin{align*}
c_\lambda(K_1, K_2) & := (1 - \lambda)K_1 + \lambda K_2 \\
& = \left\{ (1 - \lambda) p_1 + \lambda p_2 : p_1 \in K_1, p_2 \in K_2 \right\} 
\end{align*}
$$
> given by the Minkowski sum of convex bodies.

_Proof._  □

A lot of values on $K \in \mathcal{K}$ are linear in $K$.

> __Theorem [convex-body-linear].__ Fix angles $a, b \in \mathbb{R}$ so that $a < b < a + \pi$. The following values are linear in $K \in \mathcal{K}$. ^thm-convex-body-linear
> 
> 1. Support function $h_K(a)$
> 2. Vertices $v_K^\pm(a)$, $v_K(a, b)$

_Proof._  □

> __Definition [convex-space-directional-derivative].__ For any quadratic functional $f : \mathcal{V} \to \mathbb{R}$ on a convex space $\mathcal{V}$ and $K, K' \in \mathcal{V}$, define the _directional derivative_ ^def-convex-space-directional-derivative
$$
Df(K; K') := \left. \frac{d}{d \lambda} \right|_{\lambda = 0} f(c_\lambda(K, K'))
$$
> of $f$ at $K$ in the direction towards $K'$.

For any quadratic functional $f$ and a fixed $K \in \mathcal{V}$, the value $Df(K; K')$ is well-defined and always a linear functional of $K'$.

> __Lemma [derivative-calculation].__ Let $f$ be a quadratic functional on a convex space $\mathcal{V}$, so that $f(K) = h(K, K)$ for a convex-bilinear map $h : \mathcal{V} \times \mathcal{V} \to \mathbb{R}$. Then we have the following for any $K, K' \in \mathcal{V}$. ^lem-derivative-calculation
$$
Df(K; K') = h(K, K') + h(K', K) - 2 h (K, K)
$$
> So the map $Df(K; -) : \mathcal{V} \to \mathbb{R}$ is always well-defined and a linear functional. 

_Proof._ We have ^eqn-quadratic-functional
$$
\begin{split}
f(c_\lambda(K, K')) & = h(c_\lambda(K, K'), c_\lambda(K, K')) \\
& = (1 - \lambda)^2 h(K, K) + \lambda (1 - \lambda) \left( h(K, K') + h (K', K) \right) + \lambda^2 h(K', K')
\end{split}
$$
by bilinearity of $h$. Take the derivative at $\lambda = 0$. □

> __Definition [convex-space-concavity].__ A functional $f : \mathcal{V} \to \mathbb{R}$ on a convex domain $\mathcal{V}$ is _concave_ (resp. _convex_) if $f(c_\lambda(K_1, K_2)) \geq (1 - \lambda) f(K_1) + \lambda f(K_2)$ (resp. $f(c_\lambda(K_1, K_2)) \leq (1 - \lambda) f(K_1) + \lambda f(K_2)$) for all $K_1, K_2 \in \mathcal{V}$ and $\lambda \in [0, 1]$. ^def-convex-space-concavity

To prove that $K$ maximizes a concave quadratic functional $f(K)$ on $\mathcal{V}$, we only need to prove that $Df(K; -)$ is a non-positive linear functional on $\mathcal{V}$. 

> __Theorem [quadratic-variation].__ For any concave quadratic functional $f$ on a convex domain $\mathcal{V}$, the value $K \in \mathcal{V}$ maximizes $f(K)$ if and only if the linear functional $Df(K; -)$ is nonpositive. ^thm-quadratic-variation

_Proof._ Assume that $K$ is the maximizer of $f(K)$. Then for any $K' \in \mathcal{V}$, the value $f(c_\lambda(K, K'))$ over all $\lambda \in [0, 1]$ is maximized at $\lambda = 0$. So taking the derivative at $\lambda = 0$, we should have $Df(K; K') \leq 0$.

Now assume on the other hand that $K \in \mathcal{V}$ is chosen such that $Df(K; -)$ is always nonpositive. Fix an arbitrary $K' \in \mathcal{V}$. Observe that $f(c_\lambda(K, K'))$ is a polynomial $p(\lambda)$ of $\lambda \in [0, 1]$ by [[#^eqn-quadratic-functional]]. Because $f$ is concave, the polynomial $p(\lambda)$ is also concave with respect to $\lambda$ and the quadratic coefficient of $p(\lambda)$ is nonpositive. The linear coefficient of $p(\lambda)$ is $Df(K; K')$ and this is nonpositive as well. So $p(\lambda)$ is monotonically decreasing with respect to $\lambda$ and we have $f(K) \geq f(K')$ as desired. □